## 基本的なデータ抽出プロセス
1. baseURLからクローリングを行い、目的のベージ(商品等の固有ページ)のURLを見つける。
    1. ホームページ等から目的のページのハイパーリンクをスクレイピングで見つける(aタグのhrefの要素)
    2. urlを絶対パスに変更(各スクレイピングモジュールに関数ありそう))
    2. 目的のページのURLになるまで上を繰り返す。
    3. 目的のページのURLを見つける。
2. 目的ページのURLから抜き出したい情報をスクレイピング。
    - 検証などを(command + option + i) 使うとどこか見つけやすい。
    - cssセレクタ等で情報を指定。
3. DB等に保存
    - キーを一意にするなどして整合性を取る。(urlからキーを作成するなど)

### pythonでのクローリング手法
- 標準ライブラリのurlopen
使いずらいっぽい
- requestsモジュール(めっちゃ簡単にしか書かれてない)
  - HEADERの編集もやりやすい
  - GET,POST,DELETEなどが簡単に描ける
  - sessionの保存
  
aタグのhref属性からURLを取得。
相対URLの場合はpythonで絶対URLに変換。(urllib.parse等)
  

### pythonでのスクレイピング手法
- 正規表現
- XMLパーサー
XMLとHTMLは使用が微妙に違うのでやりづらい
- html.parser()
使いづらいらしい
- 外部ライブラリ
  - lxml
    - 引数にファイルやurlを取れる。
  - beautifulsoup4
    - 引数にはopenしたファイルや文字列。



---
## クローラーの実用化
クローラの分類
1. 状態を持つかどうか
  - ステートレス(普通)
  - ステートフル(5.5章)
  ログインなど何らかの情報を保持するサイト。
  cookieに対応するものを作成する必要がある。
2. javascriptを解釈するかどうか
  - javaScriptを解釈しない(普通)
  - javaScriptを解釈する(5.6章)
  Seleniumというブラウザ自動操作ツールとPhantomJSというヘッダレスブラウザによりメモリ消費を少なくクローリングできる。またjsの事項が必要なページなども絞るなどの工夫も必要。
3. 不特定多数のサイトを対象とするか
  - 特定のWEBサイトのみを対象とするクローラー(普通)
  - 不特定のWEBサイトを対象とするクローラー(googlebotなど)
  ページ構造に依存しない仕組みや、大量データを扱うため同時並列処理の技術なども必要。

### 繰り返し実行を前提として設計する(よく分かってない)
why
- 更新されたデータだけを取得する
- エラーなどで停止しても途中から再開できるようにする

what
- キャッシュを保存し一定期間アクセスしてないページにアクセスできる。(ライブラリを使用してSession情報をえる。)


### クローリング先の変更を通知する設計に
why
- サイトのcssの微細な変更で動かなくなる。その場合に人間が検知して対応できるようにする。

what
- 変化の検知
Voluptuousというライブラリが存在。データの型の検証をし、違う場合はエラーを投げる。
- 変化の通知
email,smtplibモジュールなどでメールを送る。

---
## クローラーにおける注意事項

### 著作権について

### robot.txtの指示

### XMLサイトマップ(よくわかってない)

### クロール先の負荷
what
- 同時接続数を増やしすぎない
- クロール間隔を十分にする。(1秒程度。robots。 Txtにかいてることも。)

### 連絡先の明治
HeaderにのUser-Agentヘッダーに自分のメールアドレスなどを書く。

### ステータスコードとエラー処理
why
- 相手のサーバに余計な負荷をかけないためにエラー処理が重要

what
- リトライする際に最大回数を決める。
- リトライごとにwaitの時間をより増やす。
- retryingとかいうライブラリ存在。

---
## 基礎知識
- クローリング
web上のハイパーリンクをたどって次々web上のhtmlをダウンロードする作業
- スクレイピング
htmlから必要な情報を抜き出すこと
- パーマリンク
時間が経ってもコンテンツが変わらないリンク。ajaxなどのようにurlが変化しないため、クローリングしやすい。(SEOにつよい)
- cssセレクタ、Xpath
Xpathは多機能。cssは簡潔で分かりやすい。(著書ではcss推奨)

- XMLmap

---
## 疑問点
- スクレイピング時に抜き出したい情報を見つけ出すのが検証とか以外にいい方法ないか？
- 検証でcssセレクタ抜き出した時に全部のpathが出てこない
- BeautifulSopeではcssセレクタとかを使用した抜き出しが無理？じゃあ特定の要素抜き出すの難しくね？

---

